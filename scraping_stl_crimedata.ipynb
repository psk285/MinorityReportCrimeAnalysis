{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# URL\n",
    "url = 'http://www.slmpd.org/CrimeReport.aspx'\n",
    "\n",
    "# Path to save location\n",
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(headers):\n",
    "    \"\"\"Parses out the filename from a response header.\"\"\"\n",
    "    return headers['content-disposition'].split('=')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get all the dataset eventtargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There five hidden form parameters on the page.\n",
    "__EVENTARGUMENT\n",
    "__EVENTVALIDATION\n",
    "__VIEWSTATE\n",
    "__EVENTTARGET\n",
    "__VIEWSTATEGENERATOR\n",
    "__\n",
    "\n",
    "The first page can be requested by a normal get request to the url.\n",
    "The other page requests require 'Argument' and 'Target' arguments.\n",
    "\n",
    "Target, Validation, State, and Generator are required for requests for the files. Some combination of them uniquely identify which file should be returned. The values for Target are reused, so at least one of those other parameters is necesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The first page request is a get to the url.\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "# Get the three hidden parameter values.\n",
    "payload_raw = soup.find_all('input')\n",
    "payload = {x['name']:x['value'] for x in payload_raw}\n",
    "\n",
    "# List to hold eventtargets.\n",
    "datasets_eventtargets_raw = []\n",
    "\n",
    "# Get the data for this page and store it.\n",
    "links = soup.find_all(href=re.compile(\"javascript:__doPostBack\\('.*D',''\\)\"))\n",
    "datasets_eventtargets_raw.append((1, dict(payload), links))\n",
    "    \n",
    "# Set EventTarget for page requesting.\n",
    "payload['__EVENTTARGET'] = 'GridView1'\n",
    "\n",
    "# Loop through all pages.\n",
    "for i in xrange(2,7):\n",
    "    # Set the eventargument value in the payload.\n",
    "    payload['__EVENTARGUMENT'] = 'Page$' + str(i)\n",
    "    \n",
    "    # Request the page, make a soup object, get all relevant tags.\n",
    "    r = requests.post(url, data=payload)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    # Get the three hidden parameter values.\n",
    "    inputs_raw = soup.find_all('input')\n",
    "    inputs = {x['name']:x['value'] for x in inputs_raw}\n",
    "    links = soup.find_all(href=re.compile(\"javascript:__doPostBack\\('.*D',''\\)\"))\n",
    "    datasets_eventtargets_raw.append((i, inputs, links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets_eventtargets_raw now contains a list of tuples\n",
    "1. page number\n",
    "2. dict of inputs for three of the five parameters to the js function\n",
    "3. list of js function calls that contain the argument values for requesting the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through the list of tuples and use the payload dict from each tuple to call all the files from the list in that tuple.\n",
    "pat = re.compile(r\"\\(\\'(.+?)\\'\\)?\")\n",
    "for tup in datasets_eventtargets_raw:\n",
    "    # Parse out the argument value and filename (for validating responses).\n",
    "    datasets_eventtargets = [(pat.findall(x['href'])[0], x.text) for x in tup[2]]\n",
    "    \n",
    "    # Get the three common arguments for all the files on this page.\n",
    "    payload = tup[1]\n",
    "    \n",
    "    # Add a blank fourth.\n",
    "    payload['__EVENTARGUMENT'] = ''\n",
    "    \n",
    "    # Loop through the parsed file arguments and request the files.\n",
    "    for t in datasets_eventtargets:\n",
    "        payload['__EVENTTARGET'] = t[0]\n",
    "        r = requests.post(url, data=payload)\n",
    "        if get_filename(r.headers) == t[1]:\n",
    "            # Save the file. \n",
    "            # TODO: Should rename the files so year is first so they sort correctly.\n",
    "            with open(os.path.join(path, get_filename(r.headers)), 'wb') as f:  \n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print('Error with page: ' + str(tup[0]) + ', argument: ' + t[0])\n",
    "        time.sleep(5) #to avoid connection issues with the server"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
